
此项目实现了 GANA（Gated and Attentive Neighbor Aggregation）方法，旨在解决少样本知识图谱补全（Few-Shot Knowledge Graph Completion, Few-Shot KGC）问题，主要面向长尾关系的场景。当知识图谱中某些关系仅有极少的训练三元组时，传统基于大规模嵌入学习的方法将难以有效建模，而 GANA 通过邻居感知增强与元学习框架，有效缓解了这一问题。

GANA 的核心思想是，在每一次训练任务（episode）中，模拟一个少样本学习任务，即为某个待学习的关系采样出若干三元组构成支持集（support set）与查询集（query set）。对于每个查询样本，模型需要根据支持集中提供的关系语义与尾实体模式，对头实体和关系组合预测最可能的尾实体。为了提升实体的表示质量，GANA 引入了基于注意力机制与门控机制的邻居聚合模块（Neighbor Aggregator）。该模块利用图中实体的邻接信息（即相邻实体与关系）构造邻居表示，并通过注意力权重学习其对当前实体表示的重要性，随后通过门控单元融合邻居表示与实体本身的表示，从而获得更鲁棒的实体语义。

模型整体结构分为三部分：编码器、邻居聚合模块、匹配函数。编码器通常为预训练语言模型（如 BERT 或 Transformer Encoder），用于将实体和关系文本表示编码为向量。邻居聚合模块以实体为中心，提取其在图中的一阶邻接实体与关系信息，并通过 gated-attention 的方式进行加权聚合，构成邻居增强的实体表示。最后，在匹配阶段，模型采用匹配网络的方式，将支持集中每个 (head, relation) 与其对应的 tail 进行建模，从而在查询阶段衡量一个新的 (h, r) 与所有可能尾实体的匹配得分，实现尾实体预测。

GANA 的训练基于元学习方式，特别采用 episodic training 结构，每次训练模拟一个 few-shot 任务，从而提高模型在未见关系上的泛化能力。评估阶段通常使用 Hits@K、Mean Rank 等指标，验证模型能否在仅见极少支持三元组的情况下准确预测尾实体。

该项目支持如 NELL-One、Wiki-One 等标准 few-shot KGC 数据集，并具备良好的模块化结构，便于扩展与集成其他模型如 ProtoNet、MatchingNet 或基于语言模型的增强方法。
