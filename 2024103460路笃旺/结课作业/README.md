![image](https://github.com/user-attachments/assets/1b17264b-ebf6-41bc-99ef-3a415f5c636e)
# News

**2025.1** our paper has been accepted by IEEE TIP.

**2024.2** [arxiv paper](https://arxiv.org/pdf/2402.18922) released.



## Dataset
![image](https://github.com/user-attachments/assets/03224d0d-9450-43ee-bde9-6de2e51c09f8)

you can find them [here](https://github.com/lartpang/awesome-segmentation-saliency-dataset#camouflaged-object-detection-cod).

## References

During development, we referred to the following resources:

- [MAE](https://github.com/facebookresearch/mae) - The backbone of SENet is built based on this project.
  Note that to get good results, you need to use the full pre-trained weights of MAE (including the decoder part). you can get the mae weight [here](https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_base.pth).
- [BGNet](https://github.com/thograce/BGNet) - The training process and implementation are based on this project.
