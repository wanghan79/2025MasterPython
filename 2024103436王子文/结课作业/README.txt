本结课项目是用于处理RGB、热红外（T）和深度（D）图像的多模态深度学习模型，处理流程如下：首先，三路输入图像分别通过共享权重的Swin Transformer主干网络提取四级特征金字塔（x1至x4层级，对应1/4至1/32分辨率，
通道数64-512）。此时获得初步特征后立即计算跨模态对比损失：在L1特征层进行特征投影后建立相似度矩阵，通过交叉熵损失增强模态区分性。随后进入核心处理阶段，每层特征依次通过四个关键模块：
1）动态特征交换(DFE)使用门控机制自适应融合模态特征（如RGB特征可能吸收30%热红外+70%深度信息）；2）特征校准(FC)生成三维注意力图精调特征值分布；
3）多尺度增强(MSCE)采用四分支空洞卷积（dilation=3/5/7）捕获多级上下文信息，并结合通道注意力重加权；
4）频域分解(AFD)通过FFT将特征分解为低/中/高频分量，分别优化结构和细节信息。处理后的特征通过门控注意力融合为单张特征图，同时边界感知细化模块生成边缘概率图指导特征优化。
最后进行特征重建：频率双路增强模块使用Octave卷积分离高/低频分量，分别通过专用DCT注意力强化关键信息；在四级上采样路径中（2×至32×），每级输出包含融合预测、高频细节图和低频结构图；
最终输出包括原始模态预测（pred_v/t/d）、多层融合结果（pred_fused）、频率特定预测（pred_low/high）、边缘图(pred_edge)和多层监督信号。
整个过程实现了从多模态特征提取→跨模态动态融合→频率空间优化→多级预测输出的完整计算流。
