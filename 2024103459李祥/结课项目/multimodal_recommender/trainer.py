"""
è®­ç»ƒæ¨¡å—
è´Ÿè´£æ¨¡å‹è®­ç»ƒã€éªŒè¯å’Œä¿å­˜
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
import os
import time
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
from datetime import datetime
import logging

from models import MultiModalTransformerRecommender
from evaluator import evaluate_model, RecommenderEvaluator
from config import Config


class Trainer:
    """è®­ç»ƒå™¨ç±»"""

    def __init__(self, model, train_loader, val_loader, config=None):
        self.config = config if config else Config()
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = self.config.device

        # å°†æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡
        self.model.to(self.device)

        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        self.criterion = nn.MSELoss()
        self.optimizer = optim.Adam(
            self.model.parameters(),
            lr=self.config.learning_rate,
            weight_decay=self.config.weight_decay
        )

        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='min', factor=0.5, patience=3, verbose=True
        )

        # æ—©åœæœºåˆ¶
        self.best_val_loss = float('inf')
        self.patience_counter = 0

        # è®°å½•è®­ç»ƒå†å²
        self.train_losses = []
        self.val_losses = []
        self.train_metrics_history = []
        self.val_metrics_history = []

        # TensorBoard
        self.writer = SummaryWriter(log_dir=self.config.log_dir)

        # è¯„ä¼°å™¨
        self.evaluator = RecommenderEvaluator(self.config.top_k_list)

        # åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
        self.setup_logger()

    def setup_logger(self):
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        # è·å–å½“å‰æ—¶é—´
        current_time = datetime.now().strftime("%Y%m%d_%H%M%S")

        # åˆ›å»ºæ—¥å¿—æ–‡ä»¶åï¼šæ¨¡å‹_æ•°æ®é›†_æ—¶é—´.txt
        model_name = "MultiModalTransformer"
        dataset_name = f"Synthetic_{self.config.num_users}users_{self.config.num_items}items"
        log_filename = f"{model_name}_{dataset_name}_{current_time}.txt"

        # ç¡®ä¿logsç›®å½•å­˜åœ¨
        os.makedirs(self.config.log_dir, exist_ok=True)

        # è®¾ç½®æ—¥å¿—æ–‡ä»¶è·¯å¾„
        self.log_file_path = os.path.join(self.config.log_dir, log_filename)

        # é…ç½®æ—¥å¿—è®°å½•å™¨
        self.logger = logging.getLogger('TrainingLogger')
        self.logger.setLevel(logging.INFO)

        # æ¸…é™¤å·²æœ‰çš„å¤„ç†å™¨
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)

        # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(self.log_file_path, mode='w', encoding='utf-8')
        file_handler.setLevel(logging.INFO)

        # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)

        # åˆ›å»ºæ ¼å¼å™¨
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)

        # æ·»åŠ å¤„ç†å™¨åˆ°æ—¥å¿—è®°å½•å™¨
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)

        # è®°å½•è®­ç»ƒå¼€å§‹ä¿¡æ¯
        self.log_training_header()

    def log_training_header(self):
        """è®°å½•è®­ç»ƒå¤´éƒ¨ä¿¡æ¯"""
        self.logger.info("=" * 80)
        self.logger.info("åŸºäºTransformerçš„å¤šæ¨¡æ€æ¨èç³»ç»Ÿ - è®­ç»ƒæ—¥å¿—")
        self.logger.info("=" * 80)
        self.logger.info(f"è®­ç»ƒå¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info("")

        # æ¨¡å‹ä¿¡æ¯
        self.logger.info("æ¨¡å‹é…ç½®:")
        self.logger.info(f"  æ¨¡å‹åç§°: MultiModalTransformerRecommender")
        self.logger.info(f"  åµŒå…¥ç»´åº¦: {self.config.embedding_dim}")
        self.logger.info(f"  éšè—ç»´åº¦: {self.config.hidden_dim}")
        self.logger.info(f"  æ³¨æ„åŠ›å¤´æ•°: {self.config.num_heads}")
        self.logger.info(f"  Transformerå±‚æ•°: {self.config.num_layers}")
        self.logger.info(f"  Dropoutç‡: {self.config.dropout}")
        self.logger.info("")

        # æ•°æ®é›†ä¿¡æ¯
        self.logger.info("æ•°æ®é›†é…ç½®:")
        self.logger.info(f"  æ•°æ®é›†ç±»å‹: åˆæˆæ•°æ®é›†")
        self.logger.info(f"  ç”¨æˆ·æ•°é‡: {self.config.num_users:,}")
        self.logger.info(f"  ç‰©å“æ•°é‡: {self.config.num_items:,}")
        self.logger.info(f"  äº¤äº’æ•°é‡: {self.config.num_interactions:,}")
        self.logger.info(f"  ç¨€ç–åº¦: {self.config.sparsity:.2%}")
        self.logger.info("")

        # è®­ç»ƒé…ç½®
        self.logger.info("è®­ç»ƒé…ç½®:")
        self.logger.info(f"  æ‰¹æ¬¡å¤§å°: {self.config.batch_size}")
        self.logger.info(f"  å­¦ä¹ ç‡: {self.config.learning_rate}")
        self.logger.info(f"  æƒé‡è¡°å‡: {self.config.weight_decay}")
        self.logger.info(f"  è®­ç»ƒè½®æ¬¡: {self.config.num_epochs}")
        self.logger.info(f"  æ—©åœè€å¿ƒå€¼: {self.config.patience}")
        self.logger.info(f"  è®¾å¤‡: {self.config.device}")
        self.logger.info("")

        # æ¨¡å‹å‚æ•°ä¿¡æ¯
        model_size = self.model.get_model_size()
        self.logger.info("æ¨¡å‹å‚æ•°:")
        self.logger.info(f"  æ€»å‚æ•°é‡: {model_size['total_params']:,}")
        self.logger.info(f"  å¯è®­ç»ƒå‚æ•°é‡: {model_size['trainable_params']:,}")
        self.logger.info(f"  å†»ç»“å‚æ•°é‡: {model_size['frozen_params']:,}")
        self.logger.info("")
        self.logger.info("=" * 80)
        self.logger.info("")

    def train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        num_batches = len(self.train_loader)

        progress_bar = tqdm(self.train_loader, desc="è®­ç»ƒä¸­")

        for batch_idx, batch in enumerate(progress_bar):
            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
            user_ids = batch['user_id'].to(self.device)
            item_ids = batch['item_id'].to(self.device)
            ratings = batch['rating'].to(self.device)
            text_input_ids = batch['text_input_ids'].to(self.device)
            text_attention_mask = batch['text_attention_mask'].to(self.device)
            images = batch['image'].to(self.device)

            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            predictions = self.model(user_ids, item_ids, text_input_ids,
                                   text_attention_mask, images)

            # è®¡ç®—æŸå¤±
            loss = self.criterion(predictions, ratings)

            # åå‘ä¼ æ’­
            loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)

            # æ›´æ–°å‚æ•°
            self.optimizer.step()

            total_loss += loss.item()

            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Avg Loss': f'{total_loss / (batch_idx + 1):.4f}'
            })

        avg_loss = total_loss / num_batches
        return avg_loss

    def validate_epoch(self):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0

        with torch.no_grad():
            for batch in tqdm(self.val_loader, desc="éªŒè¯ä¸­"):
                # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
                user_ids = batch['user_id'].to(self.device)
                item_ids = batch['item_id'].to(self.device)
                ratings = batch['rating'].to(self.device)
                text_input_ids = batch['text_input_ids'].to(self.device)
                text_attention_mask = batch['text_attention_mask'].to(self.device)
                images = batch['image'].to(self.device)

                # å‰å‘ä¼ æ’­
                predictions = self.model(user_ids, item_ids, text_input_ids,
                                       text_attention_mask, images)

                # è®¡ç®—æŸå¤±
                loss = self.criterion(predictions, ratings)
                total_loss += loss.item()

        avg_loss = total_loss / len(self.val_loader)
        return avg_loss

    def train(self):
        """å®Œæ•´çš„è®­ç»ƒè¿‡ç¨‹"""
        self.logger.info("å¼€å§‹è®­ç»ƒè¿‡ç¨‹...")
        self.logger.info(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(self.train_loader)}")
        self.logger.info(f"éªŒè¯æ‰¹æ¬¡æ•°: {len(self.val_loader)}")
        self.logger.info("")

        start_time = time.time()

        for epoch in range(self.config.num_epochs):
            epoch_start_time = time.time()
            self.logger.info(f"Epoch {epoch + 1}/{self.config.num_epochs}")
            self.logger.info("-" * 50)

            # è®­ç»ƒ
            train_loss = self.train_epoch()
            self.train_losses.append(train_loss)

            # éªŒè¯
            val_loss = self.validate_epoch()
            self.val_losses.append(val_loss)

            # è®¡ç®—è¯¦ç»†è¯„ä¼°æŒ‡æ ‡
            train_metrics, _ = evaluate_model(self.model, self.train_loader, self.device)
            val_metrics, _ = evaluate_model(self.model, self.val_loader, self.device)

            self.train_metrics_history.append(train_metrics)
            self.val_metrics_history.append(val_metrics)

            # å­¦ä¹ ç‡è°ƒåº¦
            current_lr = self.optimizer.param_groups[0]['lr']
            self.scheduler.step(val_loss)
            new_lr = self.optimizer.param_groups[0]['lr']

            # è®°å½•åˆ°TensorBoard
            self.writer.add_scalar('Loss/Train', train_loss, epoch)
            self.writer.add_scalar('Loss/Validation', val_loss, epoch)
            self.writer.add_scalar('Learning_Rate', new_lr, epoch)

            # è®°å½•è¯„ä¼°æŒ‡æ ‡
            for metric_name, value in val_metrics.items():
                self.writer.add_scalar(f'Metrics/Val_{metric_name}', value, epoch)

            # è®¡ç®—epochç”¨æ—¶
            epoch_time = time.time() - epoch_start_time

            # è®°å½•è¯¦ç»†çš„epochç»“æœ
            self.log_epoch_results(epoch + 1, train_loss, val_loss, train_metrics,
                                 val_metrics, current_lr, new_lr, epoch_time)

            # æ—©åœæ£€æŸ¥
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.patience_counter = 0
                self.save_model('best_model.pth')
                self.logger.info("âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹")
            else:
                self.patience_counter += 1
                self.logger.info(f"âš  éªŒè¯æŸå¤±æœªæ”¹å–„ ({self.patience_counter}/{self.config.patience})")

                if self.patience_counter >= self.config.patience:
                    self.logger.info("ğŸ›‘ æ—©åœè§¦å‘ï¼Œåœæ­¢è®­ç»ƒ")
                    break

            self.logger.info("")

        training_time = time.time() - start_time

        # è®°å½•è®­ç»ƒå®Œæˆä¿¡æ¯
        self.log_training_summary(training_time)

        # å…³é—­TensorBoard
        self.writer.close()

        return self.train_losses, self.val_losses

    def log_epoch_results(self, epoch, train_loss, val_loss, train_metrics,
                         val_metrics, current_lr, new_lr, epoch_time):
        """è®°å½•epochç»“æœ"""
        self.logger.info(f"è®­ç»ƒæŸå¤±: {train_loss:.6f}")
        self.logger.info(f"éªŒè¯æŸå¤±: {val_loss:.6f}")

        # è®°å½•ä¸»è¦è¯„ä¼°æŒ‡æ ‡
        self.logger.info(f"éªŒè¯MSE: {val_metrics.get('MSE', 0):.6f}")
        self.logger.info(f"éªŒè¯MAE: {val_metrics.get('MAE', 0):.6f}")
        self.logger.info(f"éªŒè¯RMSE: {val_metrics.get('RMSE', 0):.6f}")

        # è®°å½•æ’åºæŒ‡æ ‡
        for k in [5, 10]:
            if f'Precision@{k}' in val_metrics:
                self.logger.info(f"éªŒè¯Precision@{k}: {val_metrics[f'Precision@{k}']:.6f}")
                self.logger.info(f"éªŒè¯Recall@{k}: {val_metrics[f'Recall@{k}']:.6f}")
                self.logger.info(f"éªŒè¯NDCG@{k}: {val_metrics[f'NDCG@{k}']:.6f}")

        # è®°å½•å­¦ä¹ ç‡å˜åŒ–
        if current_lr != new_lr:
            self.logger.info(f"å­¦ä¹ ç‡è°ƒæ•´: {current_lr:.8f} â†’ {new_lr:.8f}")
        else:
            self.logger.info(f"å½“å‰å­¦ä¹ ç‡: {current_lr:.8f}")

        # è®°å½•epochç”¨æ—¶
        self.logger.info(f"Epochç”¨æ—¶: {epoch_time:.2f}ç§’")

    def log_training_summary(self, training_time):
        """è®°å½•è®­ç»ƒæ€»ç»“"""
        self.logger.info("=" * 80)
        self.logger.info("è®­ç»ƒå®Œæˆæ€»ç»“")
        self.logger.info("=" * 80)
        self.logger.info(f"è®­ç»ƒç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info(f"æ€»è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’ ({training_time/60:.2f}åˆ†é’Ÿ)")
        self.logger.info(f"å®Œæˆè½®æ¬¡: {len(self.train_losses)}/{self.config.num_epochs}")

        if self.train_losses:
            self.logger.info(f"æœ€ç»ˆè®­ç»ƒæŸå¤±: {self.train_losses[-1]:.6f}")
            self.logger.info(f"æœ€ç»ˆéªŒè¯æŸå¤±: {self.val_losses[-1]:.6f}")
            self.logger.info(f"æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.6f}")

        # è®°å½•æœ€ç»ˆè¯„ä¼°æŒ‡æ ‡
        if self.val_metrics_history:
            final_metrics = self.val_metrics_history[-1]
            self.logger.info("")
            self.logger.info("æœ€ç»ˆéªŒè¯æŒ‡æ ‡:")
            for metric_name, value in final_metrics.items():
                self.logger.info(f"  {metric_name}: {value:.6f}")

        self.logger.info("")
        self.logger.info(f"æ¨¡å‹ä¿å­˜è·¯å¾„: {self.config.model_save_path}")
        self.logger.info(f"æ—¥å¿—æ–‡ä»¶è·¯å¾„: {self.log_file_path}")
        self.logger.info("=" * 80)

    def save_model(self, filename):
        """ä¿å­˜æ¨¡å‹"""
        os.makedirs(self.config.checkpoint_dir, exist_ok=True)
        filepath = os.path.join(self.config.checkpoint_dir, filename)

        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'config': self.config,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'train_metrics_history': self.train_metrics_history,
            'val_metrics_history': self.val_metrics_history
        }, filepath)

        print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {filepath}")

    def load_model(self, filepath):
        """åŠ è½½æ¨¡å‹"""
        checkpoint = torch.load(filepath, map_location=self.device)

        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

        if 'train_losses' in checkpoint:
            self.train_losses = checkpoint['train_losses']
            self.val_losses = checkpoint['val_losses']
            self.train_metrics_history = checkpoint.get('train_metrics_history', [])
            self.val_metrics_history = checkpoint.get('val_metrics_history', [])

        print(f"æ¨¡å‹å·²ä» {filepath} åŠ è½½")

    def plot_training_curves(self, save_path=None):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        if not self.train_losses or not self.val_losses:
            print("æ²¡æœ‰è®­ç»ƒå†å²æ•°æ®å¯ç»˜åˆ¶")
            return

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # æŸå¤±æ›²çº¿
        axes[0, 0].plot(self.train_losses, label='Training Loss', color='blue')
        axes[0, 0].plot(self.val_losses, label='Validation Loss', color='red')
        axes[0, 0].set_title('Training and Validation Loss')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True)

        # MSEæ›²çº¿
        if self.val_metrics_history:
            val_mse = [m.get('MSE', 0) for m in self.val_metrics_history]
            axes[0, 1].plot(val_mse, label='Validation MSE', color='green')
            axes[0, 1].set_title('Validation MSE')
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('MSE')
            axes[0, 1].legend()
            axes[0, 1].grid(True)

        # Precision@10æ›²çº¿
        if self.val_metrics_history:
            val_precision = [m.get('Precision@10', 0) for m in self.val_metrics_history]
            axes[1, 0].plot(val_precision, label='Validation Precision@10', color='orange')
            axes[1, 0].set_title('Validation Precision@10')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Precision@10')
            axes[1, 0].legend()
            axes[1, 0].grid(True)

        # NDCG@10æ›²çº¿
        if self.val_metrics_history:
            val_ndcg = [m.get('NDCG@10', 0) for m in self.val_metrics_history]
            axes[1, 1].plot(val_ndcg, label='Validation NDCG@10', color='purple')
            axes[1, 1].set_title('Validation NDCG@10')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('NDCG@10')
            axes[1, 1].legend()
            axes[1, 1].grid(True)

        plt.tight_layout()

        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {save_path}")

        plt.close()  # å…³é—­å›¾å½¢ä»¥é‡Šæ”¾å†…å­˜

        return fig
